{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0052e984",
   "metadata": {},
   "source": [
    "# UQModel : tutorial\n",
    "\n",
    "This notebook aim to illustrate the use of UQmodels library as provider of KPI to perform system Monitoring on Time series Data. The complete pipleline can be decomposed into 3 step :\n",
    "\n",
    "1) Data load & preprocessing : (row_stored_data -> ML dataset)\n",
    "\n",
    "2) Modeling & Post processing : (ML_dataset -> pred & UQmesure -> pred & UQ-KPI)\n",
    "\n",
    "3) Visualisation & Evaluation : (Target, Pred, UQ-KPI) -> (metrics & visualisation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d124ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:0px !important; } .container { width:85% !important; } .end_space { min-height:0px !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "path = '.'\n",
    "os.chdir(path=path)\n",
    "ROOT_PATH = \"demo\"\n",
    "cwd_path = os.getcwd()\n",
    "cwd = os.path.basename(cwd_path)\n",
    "\n",
    "import numpy as np\n",
    "sys.path.insert(1, '..')\n",
    "import uqmodels as uqmodels\n",
    "\n",
    "if(True):\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(\n",
    "        '<style>'\n",
    "            '#notebook { padding-top:0px !important; } ' \n",
    "            '.container { width:85% !important; } '\n",
    "            '.end_space { min-height:0px !important; } '\n",
    "        '</style>'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6879dcac",
   "metadata": {},
   "source": [
    "# 1) Data load & preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81956ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row data : type= <class 'dict'> key dict_keys(['X', 'Y', 'context', 'X_name', 'train', 'test', 'X_split', 'context_name', 'aux', 'X_bis'])\n",
      "Pipeline : No cache data found : load data and execute the whole pipeline\n",
      "X shape: (12000, 19) y: yshape (12000, 3) Name: Synthetic_data\n"
     ]
    }
   ],
   "source": [
    "import uqmodels.processing as proc \n",
    "import uqmodels.preprocessing.Custom_Preprocessor as preproc\n",
    "from uqmodels.processing import Data_loader\n",
    "from uqmodels.processing import Pipeline\n",
    "from uqmodels.preprocessing.Custom_Preprocessor import dict_to_TS_Dataset\n",
    "import pickle\n",
    "\n",
    "#Data loading & Preprocessing\n",
    "storing = path + '/data/'\n",
    "filename = 'synthetic_dataset_multivariate.p'\n",
    "\n",
    "import pickle\n",
    "# Define a loading API\n",
    "def load_api(storing,filename,**kwargs):\n",
    "    return(pickle.load(open(storing+filename,'rb')))\n",
    "\n",
    "# Instanciate Data_loader \n",
    "data_loader = Data_loader(data_loader_api=load_api)\n",
    "\n",
    "# Apply data_loader to get rowdata\n",
    "dict_data = data_loader.load({'storing':storing,'filename':filename})\n",
    "print('Row data : type=',type(dict_data),'key',dict_data.keys())\n",
    "\n",
    "#Define Pipeline that combine data_loader and preprocesor\n",
    "\n",
    "# Here preprocessor aim only to recovers already computed feature and targets -> X = dict_data['X'],y=dict_data['y'],ect.\n",
    "preprocessor = dict_to_TS_Dataset()\n",
    "pipeline = Pipeline(data_loader=data_loader,list_processors=[preprocessor])\n",
    "\n",
    "#Define query link to load api and add a 'name' key which is recover by the preprocessor to provide a name to the dataset\n",
    "list_query = [{'storing':storing,'filename':filename,'name':'Synthetic_data'}]\n",
    "\n",
    "#It provide a data_generator (yield) that provide each processed data one by one.\n",
    "dataset_generator = pipeline.transform(list_query) \n",
    "\n",
    "# Execute preprocessing pipeline :  \n",
    "X, y, sample_weight, x_split, context, objective, name = next(dataset_generator)\n",
    "train = x_split==1\n",
    "test = np.invert(train)\n",
    "print('X shape:',X.shape,'y: yshape',y.shape,'Name:',name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d0adf",
   "metadata": {},
   "source": [
    "# 2) Modeling & Post processing : (ML_dataset -> pred & UQmesure -> pred & UQ-KPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04f35f",
   "metadata": {},
   "source": [
    "## Using UQestimator & Processing function or Processor object \n",
    "\n",
    "# Model UQ by design + Transformation d'une variance en une interval de confiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6760aac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred shape (12000, 3) Nature of UQ_mesure var_A&E UQ shape :  (2, 12000, 3)  (2:var_A,Var_E),(12000:time_step),(3:data dimension)\n",
      "Using processing function : coverage_empiric [ 1.3 10.8 90.3 98.8]  |Coverage_target : [ 2.5 16.  84.  97.5]\n",
      "Using PIs_processor : coverage_empriric [ 1.3 10.8 90.3 98.8]  |Coverage_target : [ 2.5 16.  84.  97.5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from uqmodels.modelization.ML_estimator.random_forest_UQ import RF_UQEstimator,get_params_dict\n",
    "from uqmodels.UQModel import UQModel\n",
    "import uqmodels.postprocessing.UQKPI_Processor as UQProc\n",
    "\n",
    "\n",
    "\n",
    "# PostProcesseur Instanciation that compute an epistemics lvl score\n",
    "UQEstimator_initializer = RF_UQEstimator\n",
    "UQEstimator_parameters = get_params_dict()\n",
    "\n",
    "# We can use UQestimator as standards estimator : \n",
    "UQEstimator = UQEstimator_initializer(**UQEstimator_parameters)\n",
    "UQEstimator.fit(X[train],y[train])\n",
    "pred,UQ = UQEstimator.predict(X)\n",
    "print('pred shape',pred.shape,'Nature of UQ_mesure',UQEstimator.type_UQ,'UQ shape : ',UQ.shape,' (2:var_A,Var_E),(12000:time_step),(3:data dimension)')\n",
    "\n",
    "# If we want Predictive interval from our UQmeasure :\n",
    "list_alpha = [0.025,0.16,0.84,0.975]\n",
    "\n",
    "# We can manually produce Predictive intervals form UQ_processing function :\n",
    "import uqmodels.postprocessing.UQ_processing as UQ_Process\n",
    "\n",
    "params_ = UQ_Process.fit_PI(UQ=UQ[:,train],type_UQ=UQEstimator.type_UQ,pred=pred[train],y=None,list_alpha=list_alpha)\n",
    "PIs_KPIs,_ = UQ_Process.compute_PI(UQ=UQ,type_UQ=UQEstimator.type_UQ,pred=pred,y=None,list_alpha=list_alpha,params_=params_)\n",
    "print('Using processing function : coverage_empiric',np.round((np.array(PIs_KPIs)[:,test]>y[test]).mean(axis=(1,2))*100,1),' |Coverage_target :',np.array(list_alpha)*100)\n",
    "\n",
    "# We can do the same using a post processing object : \n",
    "import uqmodels.postprocessing.UQKPI_Processor as UQProc\n",
    "\n",
    "PIs_proc = UQProc.NormalPIs_processor(KPI_parameters={'list_alpha':[0.025,0.16,0.84,0.975]})\n",
    "params_ = PIs_proc.fit(UQ=UQ[:,train],type_UQ=UQEstimator.type_UQ,pred=pred[train],y=None)\n",
    "PIs_KPIs = PIs_proc.transform(UQ=UQ,type_UQ=UQEstimator.type_UQ,pred=pred,y=None)\n",
    "print('Using PIs_processor : coverage_empriric',np.round((np.array(PIs_KPIs)[:,test]>y[test]).mean(axis=(1,2))*100,1),' |Coverage_target :',np.array(list_alpha)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873cc95a",
   "metadata": {},
   "source": [
    "## Using UQModel pipeline for predictive interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17e77bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using UQModel pipeline : coverage_empriric [ 1.3 10.6 90.2 98.8]  |Coverage_target : [ 2.5 16.  84.  97.5]\n",
      "Using UQModel pipeline : coverage_empriric [ 1.3 10.6 90.2 98.8]  | Coverage_target : [ 2.5 16.  84.  97.5]\n"
     ]
    }
   ],
   "source": [
    "from uqmodels.UQModel import UQModel\n",
    "\n",
    "# We can do the same using a UQModel object:\n",
    "PIs_proc = UQProc.NormalPIs_processor(KPI_parameters={'list_alpha':[0.025,0.16,0.84,0.975]})\n",
    "RF_UQModel = UQModel(UQEstimator_initializer,\n",
    "                     UQEstimator_parameters,\n",
    "                     name='RF_UQ',\n",
    "                     predictor=None,\n",
    "                     list_predict_KPI_processors=[PIs_proc],\n",
    "                     list_score_KPI_processors=[])\n",
    "# Firstly UQModel fit UQestimator and KPI_processor\n",
    "RF_UQModel.fit(X[train],y[train])\n",
    "pred,(PIs_KPIs) = RF_UQModel.predict(X)\n",
    "print('Using UQModel pipeline : coverage_empriric',np.round((np.array(PIs_KPIs)[:,test]>y[test]).mean(axis=(1,2))*100,1),' |Coverage_target :',np.array(list_alpha)*100)\n",
    "\n",
    "if(True): # Test load save UQModels wrapper procedure\n",
    "    # Save fitted UQEstimator and KPI-Processors\n",
    "    RF_UQModel.save('./model')\n",
    "\n",
    "    # New model \n",
    "    RF_UQModel = UQModel()\n",
    "    # Load fitted UQEstimator and KPI-Processors\n",
    "    RF_UQModel.load(path='model/RF_UQ/')\n",
    "\n",
    "#Then it apply the whole pipeline\n",
    "pred,(PIs_KPIs) = RF_UQModel.predict(X)\n",
    "\n",
    "# And perform comparaison of theorical vs real coverage\n",
    "print('Using UQModel pipeline : coverage_empriric',np.round((np.array(PIs_KPIs)[:,test]>y[test]).mean(axis=(1,2))*100,1),' | Coverage_target :',np.array(list_alpha)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c1d3c",
   "metadata": {},
   "source": [
    "## Using UQModel pipeline for multi KPI at inference  (UQMesure, Predictive interval and model unreliability score) and after observation (Anomaly score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also create a more complexe UQmodel that handle several UQKPI_Processor to build at inference (UQMesure, Predictive interval and model unreliability score) and after observation (Anomaly score)\n",
    "\n",
    "from uqmodels.processing import Cache_manager\n",
    "\n",
    "name = \"RF_UQ_tuto\"\n",
    "# Specification of the UQestimator\n",
    "UQEstimator_initializer = RF_UQEstimator\n",
    "UQEstimator_parameters = get_params_dict()\n",
    "\n",
    "# Instanciation of PostProcesseur that provide UQ measure.\n",
    "UQ_proc = UQProc.UQKPI_Processor()\n",
    "\n",
    "# PostProcesseur that compute Predictive intervals\n",
    "PIs_proc = UQProc.NormalPIs_processor(KPI_parameters={'list_alpha':[0.025,0.16,0.84,0.975]})\n",
    "\n",
    "# PostProcesseur  that compute an epistemics lvl score\n",
    "Elvl_proc = UQProc.Epistemicscorelvl_processor()\n",
    "\n",
    "# PostProcesseur Instanciation that compute Anom score\n",
    "Anom_proc_no_UQ= UQProc.Anomscore_processor(KPI_parameters={'beta':0.005,'with_born':True,'q_var':0,'k_var_e':0,'q_var_e':0,'k_var_e':0,'q_Eratio':0})\n",
    "Anom_proc_no_epistemic = UQProc.Anomscore_processor(KPI_parameters={'beta':0.005,'with_born':True,'q_var_e':0,'k_var_e':0,'q_Eratio':0})\n",
    "Anom_proc_with_epistemic = UQProc.Anomscore_processor(KPI_parameters={'beta':0.005,'with_born':True})\n",
    "\n",
    "# Instanciation of the UQmodel modeling pipeline\n",
    "RF_UQModel = UQModel(UQEstimator_initializer,\n",
    "                     UQEstimator_parameters,\n",
    "                     name=name,\n",
    "                     predictor=None,\n",
    "                     list_predict_KPI_processors=[UQ_proc,PIs_proc,Elvl_proc],\n",
    "                     list_score_KPI_processors=[Anom_proc_no_UQ,Anom_proc_no_epistemic,Anom_proc_with_epistemic])\n",
    "\n",
    "# Fit procedure\n",
    "RF_UQModel.fit(X[train],y[train])\n",
    "\n",
    "# Save fitted UQEstimator and KPI-Processors\n",
    "RF_UQModel.save('./model')\n",
    "\n",
    "# New model \n",
    "RF_UQModel = UQModel()\n",
    "\n",
    "# Load fitted UQEstimator and KPI-Processors\n",
    "RF_UQModel.load(path='model/'+name)\n",
    "    \n",
    "pred,(UQ,PIs,Elvl) = RF_UQModel.predict(X)\n",
    "KPI_ANOM1, KPI_ANOM2, KPI_ANOM3 = RF_UQModel.score(X,y)\n",
    "\n",
    "(KPI_anom_no_UQ,born_no_UQ) = KPI_ANOM1\n",
    "(KPI_anom_without_epistemic,born_without_epistemic) = KPI_ANOM2\n",
    "(KPI_anom_with_epistemic,born_with_epistemic) = KPI_ANOM3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5ff7e",
   "metadata": {},
   "source": [
    "# 3) Visualisation & Evaluation : (Target, Pred, UQ-KPI) -> (metrics & visualisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import uqmodels.visualization.visualization as visu\n",
    "\n",
    "output = pred,UQ\n",
    "f_obs = np.arange(11750,12000)\n",
    "visu.uncertainty_plot(y,output,context=None,size=(20, 7),f_obs=f_obs,name='Prediction with Aleatoric & Total uncertainty enveloppe',mode_res=False,dim=np.arange(2),type_UQ=RF_UQModel.type_UQ)\n",
    "visu.uncertainty_plot(y,output,context=None,born=born_with_epistemic,size=(20, 7),f_obs=f_obs,name='Prediction with ',mode_res=False,dim=np.arange(2),type_UQ=RF_UQModel.type_UQ)\n",
    "\n",
    "print('Q_bot emp val:2.5%', (PIs[0]<y).mean(axis=0)*100,'Q_top emp val:97',(PIs[1]<y).mean(axis=0)*100)\n",
    "print('Elvl :',[np.quantile(Elvl,q) for q in [0.50, 0.80, 0.90, 0.95, 0.975, 0.99, 0.999]])\n",
    "visu.plot_anom_matrice(score=KPI_anom_with_epistemic,true_label=dict_data['aux']['anom'][:,None],f_obs=f_obs,figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124cf4c6",
   "metadata": {},
   "source": [
    "# 3) Visualisation : zoom to one subset : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_obs = np.arange(11750,12000)\n",
    "dim = 1\n",
    "fig_s = (18,6)\n",
    "output = pred,UQ\n",
    "\n",
    "visu.plot_var(dict_data['Y'],dict_data['aux']['data_mean_dyn'],dict_data['aux'][ 'var_stat'],dict_data['aux']['impact_anom'],dict_data['aux']['anom'],f_obs,dict_data['aux']['dim'],dim,fig_s=fig_s)\n",
    "visu.uncertainty_plot(y,output,born=born_no_UQ,context=None,size=fig_s,f_obs=f_obs,name='Born_without_UQ',mode_res=False,dim=dim,type_UQ='var_A&E')\n",
    "visu.uncertainty_plot(y,output,born=born_without_epistemic,context=None,size=fig_s,f_obs=f_obs,name='Born_with_UQ',mode_res=False,dim=dim,type_UQ='var_A&E')\n",
    "visu.uncertainty_plot(y,output,born=born_with_epistemic,context=None,size=fig_s,f_obs=f_obs,name='Born_with_UQ_and_ML-risk',mode_res=False,dim=dim,type_UQ='var_A&E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd410c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uqmodels.evaluation.metrics import Generic_metric, rmse, UQ_average_coverage, UQ_sharpness, UQ_Gaussian_NLL, UQ_dEI, UQ_absolute_residu_score\n",
    "list_ctx_constraint= None\n",
    "if(True):\n",
    "    list_metrics=[ Generic_metric(rmse,'Root mean square', mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True),\n",
    "                   Generic_metric(UQ_average_coverage,\"Coverage\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_UQ=RF_UQModel.type_UQ),\n",
    "                   Generic_metric(UQ_sharpness,\"Sharpness\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_UQ=RF_UQModel.type_UQ),\n",
    "                   Generic_metric(UQ_Gaussian_NLL,\"NLL\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_UQ=RF_UQModel.type_UQ),\n",
    "                   Generic_metric(UQ_dEI,\"Epistemic_indicator\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_UQ=RF_UQModel.type_UQ),\n",
    "                   Generic_metric(UQ_absolute_residu_score,\"Anom_score\", mask=None,list_ctx_constraint=list_ctx_constraint,reduce=True,type_UQ=RF_UQModel.type_UQ)]\n",
    "\n",
    "\n",
    "commentary = ['Error increase between test and anom due to anomaly',\n",
    "              'Coverage loss between test and anom anomaly',\n",
    "              'Sharpness increase between test and after-anom to incertainty caused by the anomaly (in lag feature)',\n",
    "              'NLL increase between test and anom du to anomaly',\n",
    "              'Epistemic confidence increase between test and after-anomaly due to an OOD input that contain the abnormal lag values',\n",
    "              'Anom score between test and anom du to anomalie']\n",
    "\n",
    "print(\"Metrics evaluation apply on (pred,UQ)\")    \n",
    "\n",
    "for i,metrics in enumerate(list_metrics):\n",
    "    print(\"\")\n",
    "    mask_anom = (dict_data['aux']['anom']>0.5)\n",
    "    mask_anom_after_anom = (np.roll(dict_data['aux']['anom'],1)+np.roll(dict_data['aux']['anom'],2))>0.5\n",
    "    perf = metrics.compute(y,output,[train,test,test&mask_anom,test&mask_anom_after_anom],context=None)\n",
    "    print(metrics.name,'train :',np.round(perf[0],3),'test :',np.round(perf[1],3),'Anom :',np.round(perf[2],3),'After_anom :',np.round(perf[3],3),'|commentary :',commentary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5311ca-2f74-4b45-b88a-e6a5579fcc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5fe85-7528-445e-a6b5-03e8a828a8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
